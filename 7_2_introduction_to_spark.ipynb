{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ohmono/clustering-spark/blob/main/7_2_introduction_to_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB9u5JcF5Uck"
      },
      "source": [
        "<p><img alt=\"udeA logo\" height=\"120px\" src=\"https://github.com/freddyduitama/images/blob/master/logo.png?raw=true\" align=\"left\" hspace=\"10px\" vspace=\"0px\" style=\"width:107px;height:152px;\"></p>\n",
        "\n",
        "# <center> <font color='0B5345'> Introduction to SPARK. </font> </center>\n",
        "<font  face=\"Courier New\" size=\"2\">\n",
        "<center>Prof. John Freddy Duitama Muñoz Ph.D.</center>\n",
        "<center>Prof. Mario Giraldo. Msc.</center>\n",
        "\n",
        "<center><font face=\"Verdana\"><a  href=\"https://colab.research.google.com/drive/1YoFxA7cugsnKyJZ_LKWn3I3Ce_AIV_hl#scrollTo=Im-rLP7aPM5p\">Extensions of MapReduce</a> <a>&nbsp;&nbsp; | </a><a  href=\"https://colab.research.google.com/drive/1SgcWf2Z6jSYh5qcxOZL-QU6QZhpY87Nj#scrollTo=wUijAhrCm0-h\" >TOC</a><a>&nbsp;&nbsp;    |</a> <a>&nbsp;&nbsp;</a> <a   href=\"https://colab.research.google.com/drive/13zDbsSAVDTwVtO9LN-Zj47QTr6FWulk1\">DataFrames and Structured Data</a></font><center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVSCHzjLlZd9"
      },
      "source": [
        "##1. The SPARK Framework.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "This section introduces the SPARK low level API.\n",
        "<center><img src=\"https://github.com/freddyduitama/images/blob/master/spark-framework.png?raw=true\"  height=\"200\" width=\"400\"></center>\n",
        "<caption><center><font color='0B5345'> <u> <b>Figure 1:</b><br> </u>Spark Tools</font></center></caption>\n",
        "This lecture covers the low-level API and the most relevant RDD operations.\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-usRMJce5c9Q"
      },
      "source": [
        "## <font color='0B5345'>1.1 Set the SPARK enviroment.</font>\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "Visit this URL <a href=\"http://apache.osuosl.org/spark/\">click  </a>to verify the last SPARK and hadoop version. You must update lines 2 and 3 with the last version\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alYd_PMvWeMQ"
      },
      "source": [
        "# Install the SPARK framework . It only must be executed once.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://apache.osuosl.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvz9ToTpTgEM"
      },
      "source": [
        "#set the OS environment variables.\n",
        "import os\n",
        "from os.path import join, abspath\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz22FmAIYIvO"
      },
      "source": [
        "#import pyspark package\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setAppName(\"ejemplo\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "yVA-yR-WrcRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Mount google drive as file systems"
      ],
      "metadata": {
        "id": "PhBg5q-z7uav"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKQSxEV1PHLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e21a269-9e4e-433d-f694-87a62411ff69"
      },
      "source": [
        "# mount your google driver\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRkk8Td98b91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3dcd92b-967a-4cb5-be69-3b6c3bf7bf67"
      },
      "source": [
        "#Verify your colab directory in your google drive. You must set the path.\n",
        "!ls -l '/gdrive/My Drive/Colab Notebooks/algorithms-for-big data/lectures/data'\n",
        "path='/gdrive/My Drive/Colab Notebooks/algorithms-for-big data/lectures/data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 17862\n",
            "-rw------- 1 root root     7294 Mar  7  2019  2015-summary.csv\n",
            "-rw------- 1 root root    21622 Mar  6  2019  2015-summary.json\n",
            "-rw------- 1 root root 10327345 Apr 28  2021  auth.log\n",
            "-rw------- 1 root root     8910 May  3  2021  barrios.csv\n",
            "-rw------- 1 root root   143268 Oct  3  2022  california_housing_test1.csv\n",
            "-rw------- 1 root root   159170 Oct  3  2022  california_housing_test.csv\n",
            "-rw------- 1 root root       24 Mar  5  2019  clave-valor.txt\n",
            "-rw------- 1 root root  3602146 May  3  2021  clientes.csv\n",
            "-rw------- 1 root root   670741 Mar  5  2019  comments.txt\n",
            "-rw------- 1 root root       50 Mar  5  2019  crear-clave.txt\n",
            "-rw------- 1 root root      179 Apr 17  2021  data.gdoc\n",
            "-rw------- 1 root root       97 Apr 17  2021  data.txt\n",
            "-rw------- 1 root root      179 Nov  8  2021  datos.gdoc\n",
            "-rw------- 1 root root      440 Apr 23  2021  datos.json\n",
            "-rw------- 1 root root       91 Apr 16  2021  datos-old.txt\n",
            "-rw------- 1 root root      180 Nov  8  2021  datos.txt\n",
            "-rw------- 1 root root  1899304 May  3  2021  dispositivos.csv\n",
            "-rw------- 1 root root      157 Apr 23  2021  ejemplo.json\n",
            "-rw------- 1 root root      110 Aug 29  2022  file11.txt\n",
            "-rw------- 1 root root       49 Apr 16  2021  file1.txt\n",
            "drwx------ 2 root root     4096 Jul 28  2021  file_exercise_DataFrame\n",
            "drwx------ 2 root root     4096 Jul 28  2021  file_exercise_pyspark_graficos\n",
            "drwx------ 2 root root     4096 Aug  5  2021  file_exercise_RDD_Multiplicacion_Matrices\n",
            "drwx------ 2 root root     4096 May 31  2021  file-td-idf\n",
            "-rw------- 1 root root      179 Nov 17  2021  matrix-A.gdoc\n",
            "-rw------- 1 root root       53 Mar 21  2023  matrix-M.txt\n",
            "-rw------- 1 root root       25 Mar 21  2023  matrix-N.txt\n",
            "-rw------- 1 root root       18 Mar 21  2023  matriz-A.txt\n",
            "-rw------- 1 root root       12 Mar 21  2023  matriz-B.txt\n",
            "-rw------- 1 root root      151 Apr 25  2021 'movie (1).txt'\n",
            "-rw------- 1 root root     5544 Apr 25  2021 'movierating (1).txt'\n",
            "-rw------- 1 root root     5544 Apr 28  2021  movierating.txt\n",
            "-rw------- 1 root root      151 Apr 28  2021  movie.txt\n",
            "-rw------- 1 root root      205 Nov 19  2021  nodos.csv\n",
            "-rw------- 1 root root       98 Apr 17  2021  population.txt\n",
            "-rw------- 1 root root   697798 Mar  5  2019  Pride_and_Prejudice.txt\n",
            "drwx------ 2 root root     4096 Mar 17  2023  spark\n",
            "-rw------- 1 root root     2836 Mar  5  2019  stopList.txt\n",
            "-rw------- 1 root root      179 Mar 13  2021  test.gdoc\n",
            "-rw------- 1 root root     5882 Mar 13  2021  test.txt\n",
            "-rw------- 1 root root   697921 Mar  6  2019  texto-con-caracteres.txt\n",
            "-rw------- 1 root root      102 Oct  3  2022  valores.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H64gn4-aejia"
      },
      "source": [
        "#  INST A: Opcional..si quiere subir archivos al ambiente de trabajo desde su PC\n",
        "#from google.colab import files\n",
        "#datafile = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7toh0av9_U"
      },
      "source": [
        "## 2. RDD Operations: Transformations and actions.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>2.1. Transformations: </b> <em>map</font></em> vs <em>flatMap</em><br>\n",
        "<ul align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<li> <font color='0B5345'><b>map(func):</b></font> \tReturn a new distributed dataset formed by passing each element of the source through a function <em>func</em>. </li>\n",
        "<li> <font color='0B5345'><b>flatMap(func):</b></font> Like <em>map</em> operation, but each input element can be mapped to 0 or more output elements. As result, for each element,  <em>func</em> should return a <em>Seq</em> rather than a single element. </li>\n",
        "</ul>\n",
        "<a>Hint:</a> Each input element can be viewed as a record in a file. This record contains a string.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QegN3Z_fFC8U"
      },
      "source": [
        "<center><img src=\"https://github.com/freddyduitama/images/blob/master/map-flatmap.png?raw=true\"  height=\"200\" width=\"400\"></center>\n",
        "<caption><center><font color='0B5345'> <u> <b>Figure 2:</b><br> </u>Map ad flatMap transformations.</font></center></caption>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-DyNljO32cG"
      },
      "source": [
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>2.2. Actions:</b> <em>collect</em> vs <em>saveAsTextFile</em><br>\n",
        "<ul align=\"justify\">\n",
        "<li> <font color='0B5345'><b>collect():</b></font> Return all the elements of the dataset as an array at the driver program. This is usually useful after a <em>filter</em> or other operation that returns a sufficiently small subset of the data. </li>\n",
        "<li> <font color='0B534'><b>saveAsTextFile(path):</b></font> Write the elements of the dataset as a text file (or set of text files) in a given directory in the local filesystem, HDFS or any other Hadoop-supported file system. Spark will call the <em>toString</em> function on each element to convert it to a line of text in the file. </li>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHIEloHw07z1"
      },
      "source": [
        "<font face=\"Verdana\" size=\"2.5\">\n",
        "To download file1.txt <a href=\"https://drive.google.com/file/d/1QzWerWjtZqmqNgFjBu8zE3imVUsDO-GH/view?usp=sharing\">click</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZSYmHMnCXsI"
      },
      "source": [
        "# sc.textFile read each RDD entry as a string and create 4-partition RDD:\n",
        "RDD1 = sc.textFile(path+'/file11.txt',4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take six first rows in RDD\n",
        "RDD1.take(6)"
      ],
      "metadata": {
        "id": "Q2ZumOe_fUOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adb5c0f-6009-4aa6-baad-527a2e06123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coffee panda',\n",
              " 'happy panda',\n",
              " 'happiest panda party',\n",
              " 'coffee panda party',\n",
              " 'happy panda panda',\n",
              " 'happiest panda party']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z62Z5D7KYcoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442b8120-7436-45a5-b371-2827ed2a43b1"
      },
      "source": [
        "# split each row in RDD using \" \"\n",
        "RDD1.map(lambda line:  line.split(\" \")).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['coffee', 'panda'],\n",
              " ['happy', 'panda'],\n",
              " ['happiest', 'panda', 'party'],\n",
              " ['coffee', 'panda', 'party'],\n",
              " ['happy', 'panda', 'panda'],\n",
              " ['happiest', 'panda', 'party']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peW5uO0q3rIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30092fa2-ed44-4c12-a7fb-e070c455fc15"
      },
      "source": [
        "RDD1.flatMap(lambda line:  line.split(\" \")).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coffee',\n",
              " 'panda',\n",
              " 'happy',\n",
              " 'panda',\n",
              " 'happiest',\n",
              " 'panda',\n",
              " 'party',\n",
              " 'coffee',\n",
              " 'panda',\n",
              " 'party',\n",
              " 'happy',\n",
              " 'panda',\n",
              " 'panda',\n",
              " 'happiest',\n",
              " 'panda',\n",
              " 'party']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPrIDkntDxB4"
      },
      "source": [
        "<p align=\"jsutify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>2.3. Transformation:</b> Filter, distinct, sample<br>\n",
        "\n",
        "- <font color='0B5345'>**filter(func):**</font> Return a new dataset formed by selecting those elements of the source on which *func* returns true.\n",
        "- <font color='0B5345'>**distinct():**</font> Return a new dataset that contains the distinct elements of the source dataset.\n",
        "- <font color='0B5345'>**sample(withReplacement,fraction,seed):**</font> Sample a fraction *fraction* of the data, with or without replacement, using a given random number generator seed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgKSpzENFcR_"
      },
      "source": [
        "<p alin=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>2.4. Action:</b>count()<br>\n",
        "\n",
        "- <font color='0B5345'>**count():**</font> Return the number of elements in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIsyXlXGR6f8"
      },
      "source": [
        "<p alin=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "To download comments.txt <a href=\"https://drive.google.com/file/d/1_QPMsYlpWtzcTOZMZB4I9Z-ct8WMxqV4/view?usp=sharing\">click</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X27VqeaFJEEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ecc2cf-30f2-4ca5-96e2-95f8fc0d2e00"
      },
      "source": [
        "#  The code in this example uses the filter transformation to count how many comment lines has the file comments.txt\n",
        "sc.textFile(path+'/comments.txt',4).filter(lambda x : \"#\" in  x).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2325"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.textFile(path+'/comments.txt',4).count()"
      ],
      "metadata": {
        "id": "hut4bG3GunT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec097628-63b7-47d0-f698-acf9c0cce461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12482"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pVC6gfugtt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976ed27e-2921-4a77-905e-2b2dd0735db6"
      },
      "source": [
        "sc.textFile(path+'/comments.txt').sample(False,0.1,57).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1245"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.textFile(path+'/comments.txt').sample(False,0.1,57).take(4)"
      ],
      "metadata": {
        "id": "xCERySU8vBbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceeb60f-152f-4c9b-feec-48206ff36017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'take delight in vexing me. You have no compassion for my poor nerves.#',\n",
              " '',\n",
              " '#But I hope you will get over it, and live to see many young men of four']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TinY3igHiPyy"
      },
      "source": [
        "## 3. Some Key-Value Transformations and Actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QtJsGskidQm"
      },
      "source": [
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>3.1.  Transformation:</b> reduceByKey vs groupByKey<br>\n",
        "\n",
        "- <font color='0B5345'>**reduceByKey(func, [numPartitions]):**</font> When called on a dataset of $(K, V)$ pairs, returns a dataset of $(K, V)$ pairs where the values for each key are aggregated using the given reduce function *func*, which must be of type $(V,V) => V$. The number of reduce tasks is configurable through an optional second argument *numPartitions*.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        " - <b>Key issue:</b> the <em>reduceByKey</em> transformation implements a <em>map side combiner</em> which performs some aggregation in map side memory.\n",
        "- <font color='0B5345'>**groupByKey([numPartitions]):**</font> When called on a dataset of $(K, V)$ pairs, returns a dataset of *(K, Iterable<V>)* pairs.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "  - if you are grouping in order to perform an aggregation (such as a sum or average) over each key, using <em>reduceByKey</em> or <em>aggregateByKey</em> will yield much better performance.\n",
        "  - By default, the level of parallelism in the output depends on the number of partitions of the parent RDD. You can pass an optional *numPartitions* argument to set a different number of tasks.\n",
        "  \n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<a>Remark: </a> The Action <em>take(n)</em></a> take <em>n<em> first elements in RDD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL9NY1bZABdr"
      },
      "source": [
        "<center><img src=\"https://github.com/freddyduitama/images/blob/master/groupby-reduceby.png?raw=true\"  height=\"300\" width=\"900\"></center>\n",
        "<caption><center><font color='0B5345'> <u> <b>Figure 3:</b><br> </u>key-value transformations.</font></center></caption><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p alin=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "To download the file Pride_and_Prejudice.txt <a href=\"https://drive.google.com/file/d/1w6eCJtPjNZLADMoOGKyRNtpcKSECUsDb/view?usp=sharing\">click</a>"
      ],
      "metadata": {
        "id": "2wMK1Qxum35g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL4W8Tc3loIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358fd6cc-3c16-4cd0-eae8-716240a88782"
      },
      "source": [
        "# WordCount program.\n",
        "# 1) flatMap tokenizes each word into the lines.\n",
        "# 2) map builds <key,value> pairs.\n",
        "# 3) reduceBykey  sum values by key\n",
        "sc.textFile(path+'/Pride_and_Prejudice.txt',4) \\\n",
        "                                            .flatMap(lambda line: line.split(\" \")) \\\n",
        "                                            .map(lambda word: (word, 1))    \\\n",
        "                                            .reduceByKey(lambda a, b: a + b).take(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('PRIDE', 1),\n",
              " ('', 2465),\n",
              " ('It', 198),\n",
              " ('acknowledged,', 7),\n",
              " ('in', 1759),\n",
              " ('of', 3554),\n",
              " ('good', 153),\n",
              " ('must', 298),\n",
              " ('known', 47),\n",
              " ('may', 176),\n",
              " ('neighbourhood,', 11),\n",
              " ('he', 1036),\n",
              " ('considered', 20),\n",
              " ('other', 157),\n",
              " ('daughters.', 9),\n",
              " ('Bennet,\"', 8),\n",
              " ('lady', 36),\n",
              " ('let', 45),\n",
              " ('not.', 17),\n",
              " ('she;', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lDXPiMl6Rim"
      },
      "source": [
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>3.2.  Transformation:</b> join<br>\n",
        "\n",
        "- <font color='0B5345'>**join(otherDataset, [numPartitions]):**</font> When called on datasets of type $(K, V)$ and $(K, W)$, returns a dataset of $(K, (V, W))$ pairs with all pairs of elements for each key. Outer joins are supported through leftOuterJoin, rightOuterJoin, and fullOuterJoin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86maT0WiwXGW"
      },
      "source": [
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "\n",
        "To download matriz-M.txt <a href=\"https://drive.google.com/file/d/1OMWbxn5uUq20hTRSzZDzWl2rB2jA3Jmh/view?usp=share_link\">click</a>. <em>Format:</em> row, column, value.<br>\n",
        "To download matrix-N.txt <a href=\"https://drive.google.com/file/d/12lijk_X27SbMPzNYcftzzHVqtk4TDxmM/view?usp=share_link\">click</a>. <em>Format:</em> row, column, value.\n",
        "\n",
        "<center><img src=\"https://github.com/freddyduitama/images/blob/master/matrix-matrix.png?raw=true\"   align=\"left\" height=\"150\" width=\"450\"><center>\n",
        "\n",
        "<font color='0B5345'>\n",
        "<img src=\"https://github.com/freddyduitama/images/blob/master/matrix-matrix-1.png?raw=true\"   align=\"roght\" height=\"250\" width=\"250\">\n",
        "\n",
        "<caption><center><font color='0B5345'> <b>Figure 5: </b><br>Matrix multiplication.</font></center></caption>  \n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6aEBkq8r4D8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913536a1-e795-43b3-d974-9ac783e15907"
      },
      "source": [
        "# Matrix multiplication.\n",
        "# See Algorithms using MapReduce, lecture 4.2. section 5.\n",
        "MatrixM = sc.textFile(path+'/matrix-M.txt')\n",
        "MatrixN = sc.textFile(path+'/matrix-N.txt')\n",
        "# Prepare join input.  Map operation build (key,values) input to join.\n",
        "M=MatrixM.map(lambda record :record.split(\",\")).map(lambda item : (item[1],(item[0],item[2])))\n",
        "N=MatrixN.map(lambda record : record.split(\",\")).map(lambda item : (item[0],(item[1],item[2])))\n",
        "# execute join and group by.\n",
        "M.join(N).map(lambda x : ((x[1][0][0],x[1][1][0]), int(x[1][0][1]) * int(x[1][1][1]) )).reduceByKey(lambda a,b:a +b).sortByKey().take(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('1', '1'), 2),\n",
              " (('1', '2'), 4),\n",
              " (('2', '1'), 7),\n",
              " (('2', '2'), 5),\n",
              " (('3', '1'), 4),\n",
              " (('3', '2'), 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/gdrive/My Drive/Colab Notebooks/algorithms-for-big data/lectures/data/matrix-M.txt'"
      ],
      "metadata": {
        "id": "ms-aZ3gAqxLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2becad2-2d75-48aa-9959-541195d471bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/gdrive/My Drive/Colab Notebooks/algorithms-for-big data/lectures/data/matrix-M.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MatrixM = sc.textFile(path+'/matrix-M.txt')\n",
        "MatrixM.take(2)"
      ],
      "metadata": {
        "id": "fBAAO_wuphO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e4fb53-b676-4bec-af8e-6e3a1eac9c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1,1,1 ', '1,3,2']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step by step\n",
        "MatrixM.map(lambda record :record.split(\",\")).take(4)"
      ],
      "metadata": {
        "id": "oyhbiMubODrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d02478-6e11-4e6a-f75d-ad98f47af2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1', '1', '1 '], ['1', '3', '2'], ['2', '1', '3 '], ['2', '2', '1 ']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step by step\n",
        "MatrixM.map(lambda record :record.split(\",\")).map(lambda item:(item[1],(item[0],item[2]))).take(4)"
      ],
      "metadata": {
        "id": "N9qzFjK9NGyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180cc778-74bc-4b88-e634-484fed4d1df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', ('1', '1 ')), ('3', ('1', '2')), ('1', ('2', '3 ')), ('2', ('2', '1 '))]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.take(4)"
      ],
      "metadata": {
        "id": "p8-g7JB-iKd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c4e2a0-3209-46ec-f447-009f0265d049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', ('1', '1 ')), ('3', ('1', '2')), ('1', ('2', '3 ')), ('2', ('2', '1 '))]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N.take(6)"
      ],
      "metadata": {
        "id": "N5e41aSLr898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30bca0cf-b427-4550-f737-85e176d1ea9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', ('1', '2 ')), ('2', ('1', '1')), ('2', ('2', '1')), ('3', ('2', '2'))]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.join(N).sortByKey().take(8)"
      ],
      "metadata": {
        "id": "JDOm2OxSsSYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67aca405-b914-411c-c8a6-fe8ec3e6fef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', (('1', '1 '), ('1', '2 '))),\n",
              " ('1', (('2', '3 '), ('1', '2 '))),\n",
              " ('1', (('3', '1 '), ('1', '2 '))),\n",
              " ('2', (('2', '1 '), ('1', '1'))),\n",
              " ('2', (('2', '1 '), ('2', '1'))),\n",
              " ('2', (('3', '2 '), ('1', '1'))),\n",
              " ('2', (('3', '2 '), ('2', '1'))),\n",
              " ('3', (('1', '2'), ('2', '2')))]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.join(N).map(lambda x : ((x[1][0][0],x[1][1][0]), int(x[1][0][1]) * int(x[1][1][1]) )).sortByKey().take(8)"
      ],
      "metadata": {
        "id": "XWU3JeyglH3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e190142-0c0f-4ba2-b89d-08efe7f38f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('1', '1'), 2),\n",
              " (('1', '2'), 4),\n",
              " (('2', '1'), 6),\n",
              " (('2', '1'), 1),\n",
              " (('2', '2'), 4),\n",
              " (('2', '2'), 1),\n",
              " (('3', '1'), 2),\n",
              " (('3', '1'), 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.join(N).map(lambda x : ((x[1][0][0],x[1][1][0]), int(x[1][0][1]) * int(x[1][1][1]) )).reduceByKey(lambda a,b:a +b).sortByKey().take(8)"
      ],
      "metadata": {
        "id": "AuqARwz0OZpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e922a3-0823-414a-fe58-1cc13e132540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('1', '1'), 2),\n",
              " (('1', '2'), 4),\n",
              " (('2', '1'), 7),\n",
              " (('2', '2'), 5),\n",
              " (('3', '1'), 4),\n",
              " (('3', '2'), 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PudArXrLYQN6"
      },
      "source": [
        "## 4. Using user-defined function as argument.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "To download *Pride_and_Prejudice.txt* <a href=\"https://drive.google.com/file/d/1w6eCJtPjNZLADMoOGKyRNtpcKSECUsDb/view?usp=sharing\">click</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8MHoRhjunw7"
      },
      "source": [
        "# define función to be used in flatMap transformation.\n",
        "import re, string\n",
        "def uni_to_clean_str(x):\n",
        "    converted = x.encode('utf-8')                                               #  Universal Coded Character Set to be used.\n",
        "    punc ='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~'                                   # characters to be deleted from input string.\n",
        "    fill = '                               '                                    # blank string\n",
        "    mytable = x.maketrans(punc,fill)                                            # Create a mapping table\n",
        "    lowercased_str = x.lower()                                                  # convert string x to lower case\n",
        "    lowercased_str = lowercased_str.replace('--',' ')                           # replace string -- with ' '\n",
        "    clean_str = lowercased_str.translate(mytable)                               # translate() replaces any \"S\" characters with a \"P\" character in mytable\n",
        "    #print(\"Clean str \", clean_str)\n",
        "    return clean_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcGgGEZguvtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b273fc0d-3bcc-4428-b555-c0fbf2215df9"
      },
      "source": [
        "# Improved WordCount version.\n",
        "#  It uses the function  uni_to_clean_str to remove special characters in text files.\n",
        "one_RDD=sc.textFile(path+'/comments.txt') \\\n",
        "                                              .flatMap(lambda x: uni_to_clean_str(x)  \\\n",
        "                                              .split()).map(lambda x: (x,1)) \\\n",
        "                                              .reduceByKey(lambda x,y: x + y)\n",
        "\n",
        "print(one_RDD.take(55))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('grown-up', 1), ('daughters', 45), ('ought', 40), ('give', 122), ('of', 3472), ('her', 2168), ('own', 176), ('beauty', 24), ('in', 1792), ('cases', 5), ('think', 203), ('but', 959), ('must', 302), ('indeed', 91), ('go', 102), ('mr', 738), ('when', 360), ('he', 1239), ('into', 139), ('neighbourhood', 27), ('is', 813), ('more', 308), ('than', 271), ('i', 1989), ('engage', 5), ('assure', 38), ('consider', 31), ('only', 205), ('an', 340), ('would', 454), ('them', 420), ('lady', 186), ('are', 324), ('determined', 32), ('account', 38), ('know', 224), ('visit', 42), ('no', 474), ('newcomers', 1), ('impossible', 41), ('us', 118), ('do', 329), ('surely', 4), ('dare', 37), ('say', 153), ('very', 464), ('send', 23), ('his', 1194), ('girls', 38), ('though', 214), ('throw', 8), ('good', 173), ('others', 49), ('am', 311), ('sure', 97)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.textFile(path+'/comments.txt').flatMap(lambda x: uni_to_clean_str(x)).take(5)"
      ],
      "metadata": {
        "id": "uVeV0-AMl9wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fffddbe-4737-46f3-8f93-3f01fbef4a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['g', 'r', 'o', 'w', 'n']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN2_gTXORD7q"
      },
      "source": [
        "## 5. RDD persistence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4XkQYJyWykH"
      },
      "source": [
        "<center><img src=\"https://github.com/freddyduitama/images/blob/master/lineage-graph.png?raw=true\"  height=\"150\" width=\"400\"></center>\n",
        "  <caption><center><font color='0B5345'> <u> <b>Figure 5:</b><br> </u>Lineage graph.</font></center></caption>\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "\n",
        "- By default, each time you run an action every transformed RDD in the lineage graph must be recomputed.\n",
        "- <em>Persistence</em>  is an optimization technique in which the intermediate result of the evaluation of a lineage graph (transformed RDD) is saved in memory or disk to be able to use it later. In this way, we can use some transformed RDD’s multiple times in other to decrease the computation overhead.\n",
        "- We can make persisted RDD through **cache()** and **persist()** methods.\n",
        "Using **cache()** the default storage level is *MEMORY_ONLY*, using **persist()** we can use various storage levels: *MEMORY_ONLY*, *MEMORY_ONLY_2*, *MEMORY_AND_DISK*, *MEMORY_AND_DISK_2*, *DISK_ONLY*, *DISK_ONLY_2*, and *DISK_ONLY_3*.\n",
        "- Spark also automatically persists some intermediate data in shuffle operations (e.g. <em>reduceByKey</em>), even without users calling persist\n",
        "- <a>Hint: </a> In Python, stored objects will always be serialized with the Pickle library, so it does not matter whether you choose a serialized level.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um27t_7ghKo0"
      },
      "source": [
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "To download the file  <em>movie.txt</em> <a href=\"https://drive.google.com/file/d/1blzGJH1zV-Nh754vikV1CIIgCBPnBGf7/view?usp=sharing\">  Click</a><br>\n",
        "To download the file <em>movierating.txt</em> <a href=\"https://drive.google.com/file/d/1vVSv8kFIcmMw1JNM1XFfIBXjATyMPaue/view?usp=sharing\">  Click</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35EP3gupbPAm"
      },
      "source": [
        "### Function to extract the movie rating data from the input file\n",
        "def extractMovie(line):\n",
        "    val = line.strip()                                                            # remove  whitespaces in string\n",
        "    (moveid, name, year) = val.split(\"|\")                                         # create record with three elements.\n",
        "    return (moveid, name)\n",
        "\n",
        "### Function to extract the movie data (not the rating) from the input file\n",
        "def extractMovieRating(line):\n",
        "    val = line.strip()                                                              # remove  whitespaces in string\n",
        "    (userid, movieid, rating) = val.split(\"|\")                                      # create record with three elements.\n",
        "    return (movieid, rating)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJMFV7g2bllX"
      },
      "source": [
        "# path to input files\n",
        "file_movie = path+\"/movie.txt\"\n",
        "file_rating = path+\"/movierating.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxZwnFjCbugR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a8abdc-824f-44ea-8568-c759d5103e69"
      },
      "source": [
        "### Create RDDs from the input data\n",
        "movie = sc.textFile(file_movie)                                                 # RDD movies\n",
        "movieRatings = sc.textFile(file_rating)                                         # RDD movie ratings\n",
        "print(\"a film (move-id, name, year) :\", movie.first())\n",
        "print(\" a rating (user-id, move-id, rating): \", movieRatings.first())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a film (move-id, name, year) : 1|Avatar|2009\n",
            " a rating (user-id, move-id, rating):  1|1|1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FML16QvlyFXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58b0fdc-1bb0-436b-959e-6fda6bcceade"
      },
      "source": [
        "print(movie.getStorageLevel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serialized 1x Replicated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ZHZOpucTWO"
      },
      "source": [
        "### Without persistence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbIaUNvPbzz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ac7293-f3e9-4ac2-ac2d-1a80bd9b93de"
      },
      "source": [
        "### sum the movie ratings, group by movies.\n",
        "movieRatingsAggregated = movieRatings.map(extractMovieRating).reduceByKey(lambda a, b: int(a)+int(b))\n",
        "movieRatingsAggregated.take(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 232), ('4', 214), ('2', 203), ('3', 157)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie.map(extractMovie).take(4)"
      ],
      "metadata": {
        "id": "RbEAYslBWtGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e448580a-d31d-42b0-ae13-00948f6e38fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'Avatar'),\n",
              " ('2', 'TwoWeeksNotice'),\n",
              " ('3', 'Gravity'),\n",
              " ('4', 'FastAndFurious')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTAyA7NdcFfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c94591-aa7f-4e41-b2f9-4f7ddf348bc4"
      },
      "source": [
        "### Join the aggregated movie ratings and the movie data\n",
        "movieSortedTopList = movie.map(extractMovie).join(movieRatingsAggregated).map(lambda a: a[1]).map(lambda a: (a[1],a[0])).sortByKey(ascending=False)\n",
        "movieSortedTopList.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(232, 'Avatar'),\n",
              " (214, 'FastAndFurious'),\n",
              " (203, 'TwoWeeksNotice'),\n",
              " (199, 'TheIncredibles'),\n",
              " (196, 'TheLionKing')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-BnAN5NyWpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adf71bf-32ae-4b8d-aaf0-a1236b12e618"
      },
      "source": [
        "print(movieSortedTopList.getStorageLevel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serialized 1x Replicated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t_V9BaAcsrq"
      },
      "source": [
        "### With persistence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFNt_rhAcsr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dec129-d40b-4db9-f74b-a828c03288cc"
      },
      "source": [
        "### sum the movie ratings, group by movies and cache the RDD\n",
        "from pyspark import StorageLevel\n",
        "movieRatingsAggregated = movieRatings.map(extractMovieRating).reduceByKey(lambda a, b: int(a)+int(b))\n",
        "movieRatingsAggregated.cache()\n",
        "print(movieRatingsAggregated.getStorageLevel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory Serialized 1x Replicated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fMAeibvcsr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284ed512-1ec9-4da2-dce9-e25474e53b02"
      },
      "source": [
        "### Join the aggregated movie ratings and the movie data\n",
        "movieSortedTopList = movie.map(extractMovie).join(movieRatingsAggregated).map(lambda a: a[1]).map(lambda a: (a[1],a[0]))\n",
        "movieSortedTopList.persist(StorageLevel.MEMORY_AND_DISK_2).take(3)\n",
        "print(movieSortedTopList.getStorageLevel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disk Memory Serialized 2x Replicated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWRwdNndmkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7048c873-c93c-4c69-df4e-ed58ebe4fa8e"
      },
      "source": [
        "### Sorted movie for ratings\n",
        "top_order=movieSortedTopList.sortByKey(ascending=False)\n",
        "top_order.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(232, 'Avatar'),\n",
              " (214, 'FastAndFurious'),\n",
              " (203, 'TwoWeeksNotice'),\n",
              " (199, 'TheIncredibles'),\n",
              " (196, 'TheLionKing')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRyXbNbMpSar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c70176-99ad-4ef1-fc97-ad7d74439642"
      },
      "source": [
        "### All blocks are deleted of the persistence.\n",
        "movieSortedTopList.unpersist\n",
        "movieRatingsAggregated.unpersist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method RDD.unpersist of PythonRDD[149] at RDD at PythonRDD.scala:53>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maO9qwEK_EEV"
      },
      "source": [
        "## 6. Partition Management.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "\n",
        "- <font color='0B5345'>**sc.textFile(path,[numPartitions]):**</font> <em>numPartitions</em> defines the number of RDD partition.\n",
        "- <font color='0B5345'>**coalesce(numPartitions):**</font> Decrease the number of partitions in the RDD to <em>numPartitions</em>. Useful for running operations more efficiently after filtering down a large dataset.\n",
        "- <font color='0B5345'>**repartitionAndSortWithinPartitions(partitioner)**</font> Repartition the RDD according to the given partitioner and, within each resulting partition, sort records by their keys. This is more efficient than calling **repartition** and then sorting within each partition because it can push the sorting down into the shuffle machinery.\n",
        "- <font color='0B5345'>**RDD.glom()**</font> Return an RDD created by coalescing all elements within each partition into a list.\n",
        "\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "To download *test.txt* <a href=\"https://drive.google.com/file/d/1NM8-b1XhlOvw3Rnk5DXX61UiUoohxFvK/view?usp=sharing\">click</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nbM6ju6-8eY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e42b380-656a-4c28-e348-c082a2b3d1c6"
      },
      "source": [
        "#For  building an RDD from file, having 4 partitions.  By default, RDD partitions are equal to input (file) partitions.\n",
        "one_RDD=sc.textFile(path+'/test.txt',4)\n",
        "one_RDD.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_RDD.take(2)"
      ],
      "metadata": {
        "id": "JhATz4TXY_00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9119ef7-ef81-479e-ccae-ac10859c8658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AAAAAAAAAAAAGAGCACAC 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 46 11 9 19 29 19 0 20 7 26 14 25 12 31 26 20 10 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0',\n",
              " 'AAAAAAAAAAAGAGCACACA 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 30 6 11 23 25 10 0 16 7 17 9 17 11 19 18 14 8 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1WWSPScDswL"
      },
      "source": [
        "# Funtion to delete 0's entries in file.\n",
        "def build_record(x):\n",
        "    key = x[0]\n",
        "    rec = []\n",
        "    for i in range(len(x) -1):\n",
        "            if int(x[i+1]) > 0 :\n",
        "               rec.append((i+1,x[i+1]))\n",
        "    return (key,rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV41H0AVCGxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a048aa-1dcc-4778-e90f-2af21ec20ab6"
      },
      "source": [
        "# delete 0's entries in RDD\n",
        "one_RDD.map( lambda x : x.split(\" \")).map(lambda x : build_record(x)).take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AAAAAAAAAAAAGAGCACAC',\n",
              "  [(97, '46'),\n",
              "   (98, '11'),\n",
              "   (99, '9'),\n",
              "   (100, '19'),\n",
              "   (101, '29'),\n",
              "   (102, '19'),\n",
              "   (104, '20'),\n",
              "   (105, '7'),\n",
              "   (106, '26'),\n",
              "   (107, '14'),\n",
              "   (108, '25'),\n",
              "   (109, '12'),\n",
              "   (110, '31'),\n",
              "   (111, '26'),\n",
              "   (112, '20'),\n",
              "   (113, '10'),\n",
              "   (114, '29'),\n",
              "   (171, '7')]),\n",
              " ('AAAAAAAAAAAGAGCACACA',\n",
              "  [(97, '30'),\n",
              "   (98, '6'),\n",
              "   (99, '11'),\n",
              "   (100, '23'),\n",
              "   (101, '25'),\n",
              "   (102, '10'),\n",
              "   (104, '16'),\n",
              "   (105, '7'),\n",
              "   (106, '17'),\n",
              "   (107, '9'),\n",
              "   (108, '17'),\n",
              "   (109, '11'),\n",
              "   (110, '19'),\n",
              "   (111, '18'),\n",
              "   (112, '14'),\n",
              "   (113, '8'),\n",
              "   (114, '16')])]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_RDD.getNumPartitions()"
      ],
      "metadata": {
        "id": "C75LKaarb2dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e76079-d2ee-4456-fe47-f2494cd3200a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyaW-bdCLFUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ec1530-859e-4f7d-ab36-3e0e2e50c588"
      },
      "source": [
        "# Reduce  the number of partitions\n",
        "one_RDD.coalesce(2).getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cqSs3DLb3lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cd61e7-e9f2-4211-8416-1f224171ebbd"
      },
      "source": [
        "# build an RDD with 2 partitions and sort elements in each one.\n",
        "rdd = sc.parallelize([(0, 50), (3, 80), (2, 60), (0, 81), (3, 82), (1, 32), (1, 81), (0, 82), (3, 32)])\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 50),\n",
              " (3, 80),\n",
              " (2, 60),\n",
              " (0, 81),\n",
              " (3, 82),\n",
              " (1, 32),\n",
              " (1, 81),\n",
              " (0, 82),\n",
              " (3, 32)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.repartitionAndSortWithinPartitions(2, lambda x: x % 2, True).glom().collect()"
      ],
      "metadata": {
        "id": "I1flwTtkcezm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30dcfebf-ac23-4392-a85e-3ad9d6164e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 50), (0, 81), (0, 82), (2, 60)],\n",
              " [(1, 32), (1, 81), (3, 80), (3, 82), (3, 32)]]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J7bfvBqcMGT"
      },
      "source": [
        "## 7. Broadcast Variables.\n",
        "<p align=\"justify\"><font face=\"Verdana\" size=\"2.5\">\n",
        "<b>Definition:</b> Broadcast variables are read-only shared variables that are cached and available on all nodes in a cluster in-order to access or use by the tasks. Instead of sending this data along with every task, PySpark distributes broadcast variables to the workers using efficient broadcast algorithms to reduce communication costs.\n",
        "\n",
        "<center><img src=\"https://github.com/freddyduitama/images/blob/master/spark-application.png?raw=true\"  height=\"300\" width=\"300\"></center>\n",
        "<caption><center><font color='0B5345'> <u> <b>Figure 1:</b><br> </u>Computational model.</font></center></caption><br>\n",
        "\n",
        "><font face=\"Verdana\" size=\"2.5\"><b>Example:</b></font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-TkKl155WRv"
      },
      "source": [
        "### stopwords stores the list of English stop words. Suppose we need a read-only list that will be used for removing stop words on any English text.\n",
        "stopwords=['i','me','my','myself','we','our','ours','ourselves','you',\"you're\",\"you've\",\"you'll\",\"you'd\",'your','yours','yourself','to','she','of']\n",
        "### Use broadcast variable for caching a copy of the set of stop words at each node in the cluster instead of shipping a copy of it with each task to be executed on the nodes\n",
        "bc_stopwords = sc.broadcast(stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxoHLC4e68AQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe87f1d-dc9b-4319-d697-5cea6269a1aa"
      },
      "source": [
        "### Print values\n",
        "print(type(bc_stopwords.value))\n",
        "bc_stopwords.value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'to',\n",
              " 'she',\n",
              " 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IgDsFNTJzEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9c4f2f-797a-4f26-d8ad-1cf75e16b997"
      },
      "source": [
        "### Without the filter transformation.\n",
        "one_RDD=sc.textFile(path+'/comments.txt').\\\n",
        "flatMap(lambda x: uni_to_clean_str(x).\\\n",
        "        split()).map(lambda x: (x,1)).\\\n",
        "        reduceByKey(lambda x,y: x + y)\n",
        "print(one_RDD.take(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('grown-up', 1), ('daughters', 45), ('ought', 40), ('give', 122), ('of', 3472), ('her', 2168), ('own', 176), ('beauty', 24), ('in', 1792), ('cases', 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmgKBi2IE9I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea69ac2-8853-4641-8789-20904e2c6ce3"
      },
      "source": [
        "## using the broadcast variable into the filter transformation.\n",
        "one_RDD=sc.textFile(path+'/comments.txt').\\\n",
        "flatMap(lambda x: uni_to_clean_str(x).\\\n",
        "        split()).map(lambda x: (x,1)).\\\n",
        "        filter(lambda txt: txt[0] not in bc_stopwords.value).\\\n",
        "        reduceByKey(lambda x,y: x + y)\n",
        "print(one_RDD.take(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('grown-up', 1), ('daughters', 45), ('ought', 40), ('give', 122), ('her', 2168), ('own', 176), ('beauty', 24), ('in', 1792), ('cases', 5), ('think', 203)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo9WpFSSBSIC"
      },
      "source": [
        "<p align=\"left\"><b><font face='Courier New' color=\"black\" align=\"left\" size=4>Copyright.</font></b>\n",
        "<img alt=\"udeA logo\" height=\"120px\" src=\"https://github.com/freddyduitama/images/blob/master/in2lab.png?raw=true\" align=\"right\" hspace=\"10px\" vspace=\"0px\" height=\"120\" width=\"350\"\">\n",
        "                                                                                                                              \n",
        "<font face='Verdana' size=2>\n",
        "John Freddy Duitama Muñoz. <a href=\"https://scienti.minciencias.gov.co/cvlac/visualizador/generarCurriculoCv.do?cod_rh=0000347507\">  CvLAC</a><br>\n",
        "Universidad de Antioquia.<br>\n",
        "Apartado Aéreo 1226 | Dirección: calle 67 No. 53 - 108.<br>\n",
        "Medellín, Colombia. Sur America.\n",
        "    \n",
        "</p>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8tHFO0LBgqq"
      },
      "source": [
        "<center><b><font color='0B5345' face=\"Lucida Calligraphy,Comic Sans MS,Lucida Console\" size=\"4\">Universidad de Antioquia.</font></b> </center>"
      ]
    }
  ]
}